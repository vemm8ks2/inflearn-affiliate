# scripts/scrape_inflearn_with_sales.py
"""
ì¸í”„ëŸ° ê°•ì˜ ìŠ¤í¬ë˜í•‘ ìŠ¤í¬ë¦½íŠ¸ (ê°œì„  ë²„ì „)
- ì•ˆì •ì ì¸ ì„ íƒì ì‚¬ìš©
- ë¡œê¹… ì‹œìŠ¤í…œ ì ìš©
- í•¨ìˆ˜ ë¶„ë¦¬ ë° ëª¨ë“ˆí™”
- ì„¤ì • ê´€ë¦¬ ê°œì„ 
"""

from playwright.sync_api import sync_playwright, Locator
import json
import time
import re
from datetime import datetime
from typing import Dict, Optional, List

# ë¡œì»¬ ëª¨ë“ˆ import
from logger_config import logger
from config import config


# ============================================================================
# ë°ì´í„° ì¶”ì¶œ í—¬í¼ í•¨ìˆ˜ë“¤
# ============================================================================

def extract_with_fallback(link: Locator, selectors: List[str], validator=None) -> Optional[str]:
    """
    ì—¬ëŸ¬ ì„ íƒìë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ

    Args:
        link: Playwright Locator ê°ì²´
        selectors: ì‹œë„í•  ì„ íƒì ë¦¬ìŠ¤íŠ¸
        validator: ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ ê²€ì¦ í•¨ìˆ˜ (optional)

    Returns:
        ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë˜ëŠ” None
    """
    for selector in selectors:
        try:
            elem = link.locator(selector).first
            if elem:
                text = elem.text_content(timeout=config.ELEMENT_TIMEOUT)
                if text and text.strip():
                    text = text.strip()
                    if validator is None or validator(text):
                        return text
        except Exception as e:
            logger.debug(f"ì„ íƒì ì‹¤íŒ¨ ({selector}): {e}")
            continue
    return None


def extract_title(link: Locator) -> Optional[str]:
    """
    ê°•ì˜ ì œëª© ì¶”ì¶œ

    Args:
        link: ê°•ì˜ ë§í¬ Locator

    Returns:
        ì œëª© ë¬¸ìì—´ ë˜ëŠ” None
    """
    # ëª¨ë“  p.mantine-Text-root ì°¾ì•„ì„œ ê°€ì¥ ê¸´ í…ìŠ¤íŠ¸ ì„ íƒ (ì œëª©ì¼ í™•ë¥  ë†’ìŒ)
    try:
        text_elements = link.locator('p.mantine-Text-root').all()
        titles = []
        for elem in text_elements:
            text = elem.text_content(timeout=config.ELEMENT_TIMEOUT)
            if text and len(text.strip()) > 5:
                titles.append(text.strip())

        if titles:
            # ê°€ì¥ ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì œëª©ìœ¼ë¡œ ê°„ì£¼
            return max(titles, key=len)
    except Exception as e:
        logger.debug(f"ì œëª© ì¶”ì¶œ ì‹¤íŒ¨: {e}")

    # ëŒ€ì²´ ì „ëµ: img alt ì†ì„±
    try:
        img_elem = link.locator('img[alt*="ê°•ì˜"]').first
        if img_elem:
            alt_text = img_elem.get_attribute('alt')
            if alt_text and len(alt_text) > 5:
                return alt_text
    except Exception as e:
        logger.debug(f"ëŒ€ì²´ ì œëª© ì¶”ì¶œ ì‹¤íŒ¨: {e}")

    return None


def extract_instructor(link: Locator) -> Optional[str]:
    """
    ê°•ì‚¬ëª… ì¶”ì¶œ

    Args:
        link: ê°•ì˜ ë§í¬ Locator

    Returns:
        ê°•ì‚¬ëª… ë˜ëŠ” None
    """
    # ëª¨ë“  p.mantine-Text-root ì¤‘ ì§§ì€ í…ìŠ¤íŠ¸ ì„ íƒ (ê°•ì‚¬ëª…ì¼ í™•ë¥  ë†’ìŒ)
    try:
        text_elements = link.locator('p.mantine-Text-root').all()
        instructors = []
        for elem in text_elements:
            text = elem.text_content(timeout=config.ELEMENT_TIMEOUT)
            if text and 2 < len(text.strip()) < 20:  # ê°•ì‚¬ëª…ì€ ë³´í†µ ì§§ìŒ
                instructors.append(text.strip())

        if len(instructors) >= 2:
            # ë‘ ë²ˆì§¸ë¡œ ì§§ì€ í…ìŠ¤íŠ¸ë¥¼ ê°•ì‚¬ëª…ìœ¼ë¡œ ê°„ì£¼ (ì²«ë²ˆì§¸ëŠ” ì¹´í…Œê³ ë¦¬ì¼ ìˆ˜ ìˆìŒ)
            return sorted(instructors, key=len)[1] if len(instructors) > 1 else instructors[0]
        elif instructors:
            return instructors[0]
    except Exception as e:
        logger.debug(f"ê°•ì‚¬ëª… ì¶”ì¶œ ì‹¤íŒ¨: {e}")

    return None


def extract_thumbnail(link: Locator) -> Optional[str]:
    """
    ì¸ë„¤ì¼ ì´ë¯¸ì§€ URL ì¶”ì¶œ

    Args:
        link: ê°•ì˜ ë§í¬ Locator

    Returns:
        ì´ë¯¸ì§€ URL ë˜ëŠ” None
    """
    try:
        img_elem = link.locator('picture img').first
        if img_elem:
            img_src = img_elem.get_attribute('src')
            if img_src:
                return img_src
    except Exception as e:
        logger.debug(f"ì¸ë„¤ì¼ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

    return None


def parse_price(price_text: str) -> int:
    """
    ê°€ê²© ë¬¸ìì—´ì„ ì •ìˆ˜ë¡œ ë³€í™˜

    Args:
        price_text: "â‚©99,000" í˜•ì‹ì˜ ë¬¸ìì—´

    Returns:
        ì •ìˆ˜ ê°€ê²© (ë¬´ë£ŒëŠ” 0)
    """
    if not price_text or price_text == 'ë¬´ë£Œ':
        return 0
    try:
        return int(price_text.replace('â‚©', '').replace(',', '').strip())
    except ValueError:
        return 0


def extract_price_info(link: Locator) -> Dict[str, Optional[any]]:
    """
    ê°€ê²© ì •ë³´ ì¶”ì¶œ (ì •ê°€, í• ì¸ê°€, í• ì¸ìœ¨)

    Args:
        link: ê°•ì˜ ë§í¬ Locator

    Returns:
        ê°€ê²© ì •ë³´ ë”•ì…”ë„ˆë¦¬
    """
    result = {
        'original_price': None,
        'sale_price': None,
        'price': None,
        'discount_rate': None,
    }

    try:
        # ëª¨ë“  p.mantine-Text-rootì—ì„œ ê°€ê²© íŒ¨í„´ ì°¾ê¸°
        text_elements = link.locator('p.mantine-Text-root').all()
        prices = []

        for elem in text_elements:
            text = elem.text_content(timeout=config.ELEMENT_TIMEOUT)
            if text and 'â‚©' in text:
                prices.append(text.strip())

        if not prices:
            # ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ê°€ê²© íŒ¨í„´ ì¶”ì¶œ
            all_text = link.text_content()
            if 'ë¬´ë£Œ' in all_text:
                result['original_price'] = 'ë¬´ë£Œ'
                result['price'] = 'ë¬´ë£Œ'
                return result
            elif 'â‚©' in all_text:
                price_match = re.search(r'â‚©[\d,]+', all_text)
                if price_match:
                    result['original_price'] = price_match.group()
                    result['price'] = price_match.group()
            return result

        # ê°€ê²©ì´ 2ê°œ ì´ìƒì´ë©´ ì •ê°€/í• ì¸ê°€ë¡œ ê°„ì£¼
        if len(prices) >= 2:
            # ì¼ë°˜ì ìœ¼ë¡œ ì •ê°€ê°€ ë” ë†’ìŒ
            price_nums = [(p, parse_price(p)) for p in prices]
            price_nums.sort(key=lambda x: x[1], reverse=True)

            original_price = price_nums[0][0]
            sale_price = price_nums[1][0]

            result['original_price'] = original_price
            result['sale_price'] = sale_price
            result['price'] = sale_price

            # í• ì¸ìœ¨ ê³„ì‚°
            orig_num = parse_price(original_price)
            sale_num = parse_price(sale_price)

            if orig_num > 0 and sale_num > 0 and orig_num > sale_num:
                discount_rate = round(((orig_num - sale_num) / orig_num) * 100, 1)
                result['discount_rate'] = discount_rate

        elif len(prices) == 1:
            # ê°€ê²©ì´ 1ê°œë©´ ì •ê°€ë¡œ ì²˜ë¦¬
            result['original_price'] = prices[0]
            result['price'] = prices[0]

    except Exception as e:
        logger.debug(f"ê°€ê²© ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

    return result


def extract_rating(link: Locator) -> Optional[float]:
    """
    í‰ì  ì¶”ì¶œ

    Args:
        link: ê°•ì˜ ë§í¬ Locator

    Returns:
        í‰ì  (0-5) ë˜ëŠ” None
    """
    try:
        text_elements = link.locator('p.mantine-Text-root').all()

        for elem in text_elements:
            text = elem.text_content(timeout=config.ELEMENT_TIMEOUT)
            if text:
                text = text.strip()
                # ìˆ«ì íŒ¨í„´ ë§¤ì¹­ (ì†Œìˆ˜ì  í¬í•¨)
                if re.match(r'^\d+(\.\d+)?$', text):
                    rating_value = float(text)
                    # âœ… Priority 3: í‰ì  ê²€ì¦ ë²”ìœ„ ìˆ˜ì • (0-100 â†’ 0-5)
                    if 0 <= rating_value <= 5:
                        return rating_value
                    else:
                        logger.warning(f"ë¹„ì •ìƒ í‰ì  ê°’: {rating_value}")

    except Exception as e:
        logger.debug(f"í‰ì  ì¶”ì¶œ ì‹¤íŒ¨: {e}")

    return None


def extract_review_count(link: Locator) -> Optional[int]:
    """
    ë¦¬ë·° ìˆ˜ ì¶”ì¶œ

    Args:
        link: ê°•ì˜ ë§í¬ Locator

    Returns:
        ë¦¬ë·° ìˆ˜ ë˜ëŠ” None
    """
    try:
        text_elements = link.locator('p.mantine-Text-root').all()

        for elem in text_elements:
            text = elem.text_content(timeout=config.ELEMENT_TIMEOUT)
            if text:
                # (123) íŒ¨í„´ ë§¤ì¹­
                review_match = re.search(r'\((\d+)\)', text)
                if review_match:
                    return int(review_match.group(1))

    except Exception as e:
        logger.debug(f"ë¦¬ë·° ìˆ˜ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

    return None


def extract_student_count(link: Locator) -> Optional[str]:
    """
    ìˆ˜ê°•ìƒ ìˆ˜ ì¶”ì¶œ

    Args:
        link: ê°•ì˜ ë§í¬ Locator

    Returns:
        ìˆ˜ê°•ìƒ ìˆ˜ ë¬¸ìì—´ ë˜ëŠ” None
    """
    try:
        # span íƒœê·¸ì—ì„œ ìˆ˜ê°•ìƒ ìˆ˜ íŒ¨í„´ ì°¾ê¸°
        span_elements = link.locator('span').all()

        for elem in span_elements:
            text = elem.text_content(timeout=config.ELEMENT_TIMEOUT)
            if text:
                text = text.strip()
                # 500+, 1.2K ë“±ì˜ íŒ¨í„´ ë§¤ì¹­
                if re.search(r'\d+\.?\d*[K+]?', text):
                    return text

    except Exception as e:
        logger.debug(f"ìˆ˜ê°•ìƒ ìˆ˜ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

    return None


def extract_course_data(link: Locator, idx: int) -> Dict[str, any]:
    """
    ê°•ì˜ í•˜ë‚˜ì˜ ëª¨ë“  ë°ì´í„° ì¶”ì¶œ

    Args:
        link: ê°•ì˜ ë§í¬ Locator
        idx: ê°•ì˜ ì¸ë±ìŠ¤

    Returns:
        ê°•ì˜ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
    """
    try:
        # URL ë° course_id
        url = link.get_attribute('href')
        course_id = None
        if url:
            course_id = url.split('/course/')[-1].split('?')[0]

        # ëª¨ë“  í•„ë“œ ì¶”ì¶œ
        course = {
            'url': url,
            'course_id': course_id,
            'title': extract_title(link),
            'instructor': extract_instructor(link),
            'thumbnail_url': extract_thumbnail(link),
            **extract_price_info(link),
            'rating': extract_rating(link),
            'review_count': extract_review_count(link),
            'student_count': extract_student_count(link),
            'scraped_at': datetime.now().isoformat(),
            'source': 'inflearn',
        }

        return course

    except Exception as e:
        logger.error(f"ê°•ì˜ {idx+1} ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨", exc_info=True)
        return {}


def is_valid_course(course: Dict[str, any]) -> bool:
    """
    ê°•ì˜ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦

    Args:
        course: ê°•ì˜ ë°ì´í„° ë”•ì…”ë„ˆë¦¬

    Returns:
        ìœ íš¨ ì—¬ë¶€
    """
    if not course.get('title') or not course.get('url'):
        return False

    # ì œëª© ê¸¸ì´ ê²€ì¦
    if len(course.get('title', '')) < 3:
        logger.warning(f"ì œëª©ì´ ë„ˆë¬´ ì§§ìŒ: {course.get('title')}")
        return False

    return True


def log_course_info(course: Dict[str, any], idx: int):
    """
    ìˆ˜ì§‘í•œ ê°•ì˜ ì •ë³´ ë¡œê¹…

    Args:
        course: ê°•ì˜ ë°ì´í„°
        idx: ì¸ë±ìŠ¤
    """
    logger.info(f"  [{idx+1}] {course.get('title', 'N/A')[:40]}...")
    logger.info(f"       ê°•ì‚¬: {course.get('instructor', 'N/A')}")

    # ê°€ê²© ì •ë³´ ì¶œë ¥
    if course.get('sale_price'):
        logger.info(f"       ì •ê°€: {course.get('original_price', 'N/A')}, "
                   f"í• ì¸ê°€: {course.get('sale_price')}, "
                   f"í• ì¸ìœ¨: {course.get('discount_rate', 'N/A')}%")
    else:
        logger.info(f"       ê°€ê²©: {course.get('original_price', 'N/A')}")

    logger.info(f"       í‰ì : {course.get('rating', 'N/A')}, "
               f"ë¦¬ë·°: {course.get('review_count', 'N/A')}, "
               f"ìˆ˜ê°•ìƒ: {course.get('student_count', 'N/A')}")


# ============================================================================
# ë©”ì¸ ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜
# ============================================================================

def scrape_inflearn_courses(max_courses: Optional[int] = None, headless: Optional[bool] = None) -> List[Dict]:
    """
    ì¸í”„ëŸ° ê°•ì˜ ëª©ë¡ ìŠ¤í¬ë˜í•‘ (ë¦¬íŒ©í† ë§ ë²„ì „)

    Args:
        max_courses: ìˆ˜ì§‘í•  ìµœëŒ€ ê°•ì˜ ìˆ˜ (ê¸°ë³¸ê°’: config.MAX_COURSES)
        headless: ë¸Œë¼ìš°ì € ìˆ¨ê¹€ ëª¨ë“œ (ê¸°ë³¸ê°’: config.HEADLESS)

    Returns:
        ê°•ì˜ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
    """
    # ê¸°ë³¸ê°’ ì„¤ì •
    max_courses = max_courses if max_courses is not None else config.MAX_COURSES
    headless = headless if headless is not None else config.HEADLESS

    logger.info("=" * 60)
    logger.info("ğŸš€ ì¸í”„ëŸ° ê°•ì˜ ìŠ¤í¬ë˜í•‘ ì‹œì‘")
    logger.info(f"ì„¤ì •: max_courses={max_courses}, headless={headless}")
    logger.info("=" * 60)

    courses = []

    with sync_playwright() as p:
        # ë¸Œë¼ìš°ì € ì‹¤í–‰
        browser = p.chromium.launch(headless=headless)
        page = browser.new_page()

        try:
            # í˜ì´ì§€ ì´ë™
            url = f"{config.BASE_URL}/{config.CATEGORY}"
            logger.info(f"ğŸŒ í˜ì´ì§€ ì ‘ì† ì¤‘: {url}")
            page.goto(url, wait_until="domcontentloaded", timeout=config.PAGE_LOAD_TIMEOUT)
            time.sleep(2)

            # ìŠ¤í¬ë¡¤í•˜ì—¬ ì½˜í…ì¸  ë¡œë“œ
            logger.info("ğŸ“œ í˜ì´ì§€ ìŠ¤í¬ë¡¤ ì¤‘...")
            for i in range(3):
                page.evaluate("window.scrollBy(0, window.innerHeight)")
                time.sleep(config.SCROLL_DELAY)
                logger.debug(f"ìŠ¤í¬ë¡¤ {i+1}/3 ì™„ë£Œ")

            # ê°•ì˜ ë§í¬ ìˆ˜ì§‘
            logger.info("ğŸ” ê°•ì˜ ë§í¬ ìˆ˜ì§‘ ì¤‘...")
            course_links = page.locator('a[href*="/course/"]').all()
            logger.info(f"âœ… {len(course_links)}ê°œì˜ ê°•ì˜ ë°œê²¬")

            # ë°ì´í„° ì¶”ì¶œ
            logger.info(f"ğŸ“Š ë°ì´í„° ì¶”ì¶œ ì¤‘ (ìµœëŒ€ {max_courses}ê°œ)...")
            for idx, link in enumerate(course_links[:max_courses]):
                try:
                    course_data = extract_course_data(link, idx)

                    if is_valid_course(course_data):
                        courses.append(course_data)
                        log_course_info(course_data, idx)
                    else:
                        logger.warning(f"ê°•ì˜ {idx+1} ê²€ì¦ ì‹¤íŒ¨")

                except Exception as e:
                    logger.error(f"ê°•ì˜ {idx+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
                    continue

            # ë””ë²„ê·¸ íŒŒì¼ ì €ì¥
            logger.info("ğŸ’¾ ë””ë²„ê·¸ íŒŒì¼ ì €ì¥ ì¤‘...")
            page.screenshot(path=config.SCREENSHOT_PATH)
            logger.info(f"ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {config.SCREENSHOT_PATH}")

            html_content = page.content()
            with open(config.HTML_SOURCE_PATH, "w", encoding="utf-8") as f:
                f.write(html_content)
            logger.info(f"HTML ì†ŒìŠ¤ ì €ì¥: {config.HTML_SOURCE_PATH}")

        except Exception as e:
            logger.error(f"ìŠ¤í¬ë˜í•‘ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)

        finally:
            browser.close()
            logger.debug("ë¸Œë¼ìš°ì € ì¢…ë£Œ")

    logger.info(f"\nâœ… ì´ {len(courses)}ê°œ ê°•ì˜ ìˆ˜ì§‘ ì™„ë£Œ")
    return courses


def save_to_json(courses: List[Dict], filename: Optional[str] = None):
    """
    ìˆ˜ì§‘í•œ ê°•ì˜ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥

    Args:
        courses: ê°•ì˜ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        filename: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: config.JSON_OUTPUT)
    """
    filename = filename or config.JSON_OUTPUT

    try:
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(courses, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ’¾ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filename}")
    except Exception as e:
        logger.error(f"JSON ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)


def print_summary(courses: List[Dict]):
    """
    ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ ì¶œë ¥

    Args:
        courses: ê°•ì˜ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    if not courses:
        logger.warning("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    logger.info("\nğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½:")
    logger.info(f"  - ì´ ê°•ì˜ ìˆ˜: {len(courses)}")
    logger.info(f"  - ì œëª© ìˆëŠ” ê°•ì˜: {sum(1 for c in courses if c.get('title'))}")
    logger.info(f"  - ê°•ì‚¬ëª… ìˆëŠ” ê°•ì˜: {sum(1 for c in courses if c.get('instructor'))}")
    logger.info(f"  - URL ìˆëŠ” ê°•ì˜: {sum(1 for c in courses if c.get('url'))}")
    logger.info(f"  - ì¸ë„¤ì¼ ìˆëŠ” ê°•ì˜: {sum(1 for c in courses if c.get('thumbnail_url'))}")
    logger.info(f"  - ì •ê°€ ìˆëŠ” ê°•ì˜: {sum(1 for c in courses if c.get('original_price'))}")
    logger.info(f"  - í• ì¸ê°€ ìˆëŠ” ê°•ì˜: {sum(1 for c in courses if c.get('sale_price'))}")
    logger.info(f"  - í• ì¸ìœ¨ ìˆëŠ” ê°•ì˜: {sum(1 for c in courses if c.get('discount_rate'))}")
    logger.info(f"  - í‰ì  ìˆëŠ” ê°•ì˜: {sum(1 for c in courses if c.get('rating'))}")
    logger.info(f"  - ë¦¬ë·° ìˆ˜ ìˆëŠ” ê°•ì˜: {sum(1 for c in courses if c.get('review_count'))}")
    logger.info(f"  - ìˆ˜ê°•ìƒ ìˆ˜ ìˆëŠ” ê°•ì˜: {sum(1 for c in courses if c.get('student_count'))}")


# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # ìŠ¤í¬ë˜í•‘ ì‹¤í–‰
        courses = scrape_inflearn_courses()

        if courses:
            # JSON ì €ì¥
            save_to_json(courses)

            # ê²°ê³¼ ìš”ì•½
            print_summary(courses)
        else:
            logger.warning("ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        logger.info("\n" + "=" * 60)
        logger.info("âœ… ì‘ì—… ì™„ë£Œ")
        logger.info("=" * 60)

    except KeyboardInterrupt:
        logger.warning("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)


if __name__ == "__main__":
    main()
