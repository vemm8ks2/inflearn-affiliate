# scripts/src/scraper.py
"""
ì¸í”„ëŸ° ê°•ì˜ ìŠ¤í¬ë˜í•‘ ìŠ¤í¬ë¦½íŠ¸ (API ë²„ì „)
- API ì§ì ‘ í˜¸ì¶œë¡œ ì•ˆì •ì„± í–¥ìƒ
- ë¡œê¹… ì‹œìŠ¤í…œ ì ìš©
- í•¨ìˆ˜ ë¶„ë¦¬ ë° ëª¨ë“ˆí™”
- ì„¤ì • ê´€ë¦¬ ê°œì„ 
- Phase 6: Playwright ë ˆê±°ì‹œ ì½”ë“œ ì™„ì „ ì œê±°
"""

import json
import time
from datetime import datetime, timezone
from typing import Dict, Optional, List

# ë¡œì»¬ ëª¨ë“ˆ import
from src.logger_config import logger
from src.config import config
from src.db_utils import upsert_courses


# ============================================================================
# API ê¸°ë°˜ ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜
# ============================================================================

def scrape_inflearn_courses_api(max_courses: Optional[int] = None) -> tuple[List[Dict], Dict]:
    """
    ì¸í”„ëŸ° ê°•ì˜ ëª©ë¡ ìŠ¤í¬ë˜í•‘ (API ë²„ì „ - ë©”íƒ€ë°ì´í„° í¬í•¨)

    Args:
        max_courses: ìˆ˜ì§‘í•  ìµœëŒ€ ê°•ì˜ ìˆ˜ (ê¸°ë³¸ê°’: config.MAX_COURSES)

    Returns:
        tuple: (ê°•ì˜ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸, ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬)
    """
    from src.api_client import InflearnAPIClient

    # ê¸°ë³¸ê°’ ì„¤ì •
    max_courses = max_courses if max_courses is not None else config.MAX_COURSES

    # ìŠ¤í¬ë˜í•‘ ì‹œì‘ ì‹œê°„ ê¸°ë¡
    start_time = time.time()
    start_datetime = datetime.now(timezone.utc)

    logger.info("=" * 60)
    logger.info("ğŸš€ ì¸í”„ëŸ° ê°•ì˜ ìŠ¤í¬ë˜í•‘ ì‹œì‘ (API ë²„ì „)")
    logger.info(f"ì„¤ì •: max_courses={max_courses}")
    logger.info("=" * 60)

    try:
        # API í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        client = InflearnAPIClient(language="ko")

        # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        logger.info(f"ğŸ” ê°•ì˜ ìˆ˜ì§‘ ì‹œì‘ (ëª©í‘œ: {max_courses}ê°œ)")
        courses = client.get_all_courses(max_courses=max_courses, category=config.CATEGORY)

        # ìŠ¤í¬ë˜í•‘ ì¢…ë£Œ ì‹œê°„ ê³„ì‚°
        end_time = time.time()
        duration = round(end_time - start_time, 2)

        # ë©”íƒ€ë°ì´í„° ìƒì„±
        metadata = {
            "version": "1.0.0",
            "scraper_version": "4.0.0",  # Phase 6: Playwright ì½”ë“œ ì™„ì „ ì œê±°
            "total_courses": len(courses),
            "failed_courses": 0,  # API ë°©ì‹ì€ ì‹¤íŒ¨ ì—†ìŒ
            "scraped_at": start_datetime.isoformat(),
            "scraping_duration_seconds": duration,
            "config": {
                "max_courses": max_courses,
                "category": config.CATEGORY,
                "base_url": "https://course-api.inflearn.com/client/api/v2",
                "method": "API"  # API ë°©ì‹ ëª…ì‹œ
            }
        }

        logger.info(f"\nâœ… ì´ {len(courses)}ê°œ ê°•ì˜ ìˆ˜ì§‘ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {duration}ì´ˆ)")
        return courses, metadata

    except Exception as e:
        logger.error(f"ìŠ¤í¬ë˜í•‘ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        # ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ë©”íƒ€ë°ì´í„° ë°˜í™˜
        end_time = time.time()
        duration = round(end_time - start_time, 2)
        metadata = {
            "version": "1.0.0",
            "scraper_version": "4.0.0",
            "total_courses": 0,
            "scraped_at": start_datetime.isoformat(),
            "scraping_duration_seconds": duration,
            "config": {
                "max_courses": max_courses,
                "category": config.CATEGORY,
                "method": "API"
            },
            "error": str(e)
        }
        return [], metadata


# ============================================================================
# ë°ì´í„° ì €ì¥ ë° ì¶œë ¥ í•¨ìˆ˜
# ============================================================================

def save_to_json(courses: List[Dict], metadata: Optional[Dict] = None, filename: Optional[str] = None):
    """
    ìˆ˜ì§‘í•œ ê°•ì˜ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥ (ë©”íƒ€ë°ì´í„° í¬í•¨)

    Args:
        courses: ê°•ì˜ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        metadata: ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬ (ì„ íƒì )
        filename: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: config.JSON_OUTPUT)
    """
    filename = filename or config.JSON_OUTPUT

    try:
        # ë©”íƒ€ë°ì´í„°ê°€ ìˆìœ¼ë©´ êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ì €ì¥
        if metadata:
            output_data = {
                "metadata": metadata,
                "courses": courses
            }
        else:
            # í•˜ìœ„ í˜¸í™˜ì„±: ë©”íƒ€ë°ì´í„° ì—†ìœ¼ë©´ ê¸°ì¡´ í˜•ì‹ ìœ ì§€
            output_data = courses

        with open(filename, "w", encoding="utf-8") as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ’¾ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filename}")
    except Exception as e:
        logger.error(f"JSON ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)


def print_summary(courses: List[Dict]):
    """
    ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ ì¶œë ¥

    Args:
        courses: ê°•ì˜ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    if not courses:
        logger.warning("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    logger.info("\nğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½:")
    logger.info(f"  - ì´ ê°•ì˜ ìˆ˜: {len(courses)}")
    logger.info(f"  - ì œëª© ìˆëŠ” ê°•ì˜: {sum(1 for c in courses if c.get('title'))}")
    logger.info(f"  - ê°•ì‚¬ëª… ìˆëŠ” ê°•ì˜: {sum(1 for c in courses if c.get('instructor'))}")
    logger.info(f"  - URL ìˆëŠ” ê°•ì˜: {sum(1 for c in courses if c.get('url'))}")
    logger.info(f"  - ì¸ë„¤ì¼ ìˆëŠ” ê°•ì˜: {sum(1 for c in courses if c.get('thumbnail_url'))}")
    logger.info(f"  - ì •ê°€ ìˆëŠ” ê°•ì˜: {sum(1 for c in courses if c.get('original_price'))}")
    logger.info(f"  - í• ì¸ê°€ ìˆëŠ” ê°•ì˜: {sum(1 for c in courses if c.get('sale_price'))}")
    logger.info(f"  - í• ì¸ìœ¨ ìˆëŠ” ê°•ì˜: {sum(1 for c in courses if c.get('discount_rate'))}")
    logger.info(f"  - í‰ì  ìˆëŠ” ê°•ì˜: {sum(1 for c in courses if c.get('rating'))}")
    logger.info(f"  - ë¦¬ë·° ìˆ˜ ìˆëŠ” ê°•ì˜: {sum(1 for c in courses if c.get('review_count'))}")
    logger.info(f"  - ìˆ˜ê°•ìƒ ìˆ˜ ìˆëŠ” ê°•ì˜: {sum(1 for c in courses if c.get('student_count'))}")


# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # ìŠ¤í¬ë˜í•‘ ì‹¤í–‰ (API ë²„ì „ - ë©”íƒ€ë°ì´í„° í¬í•¨)
        courses, metadata = scrape_inflearn_courses_api()

        if courses:
            # JSON ì €ì¥ (ë©”íƒ€ë°ì´í„° í¬í•¨)
            save_to_json(courses, metadata)

            # Supabase ì €ì¥
            logger.info("\nğŸ’¾ Supabase ì €ì¥ ì¤‘...")
            saved_count = upsert_courses(courses)

            # ê²°ê³¼ ìš”ì•½
            print_summary(courses)

            # ë©”íƒ€ë°ì´í„° ìš”ì•½ ì¶œë ¥
            logger.info("\nğŸ“‹ ë©”íƒ€ë°ì´í„°:")
            logger.info(f"  - ë°ì´í„° ë²„ì „: {metadata['version']}")
            logger.info(f"  - ìŠ¤í¬ë˜í¼ ë²„ì „: {metadata['scraper_version']}")
            logger.info(f"  - ìˆ˜ì§‘ ì‹œê°„: {metadata['scraped_at']}")
            logger.info(f"  - ì†Œìš” ì‹œê°„: {metadata['scraping_duration_seconds']}ì´ˆ")

            # ìµœì¢… ê²°ê³¼ ìš”ì•½
            logger.info("\nğŸ“Š ìµœì¢… ê²°ê³¼:")
            logger.info(f"  - ìˆ˜ì§‘: {len(courses)}ê°œ")
            logger.info(f"  - ì €ì¥: {saved_count}ê°œ")
            logger.info(f"  - ì‹œê°„: {datetime.now()}")
        else:
            logger.warning("ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        logger.info("\n" + "=" * 60)
        logger.info("âœ… ì‘ì—… ì™„ë£Œ")
        logger.info("=" * 60)

    except KeyboardInterrupt:
        logger.warning("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)


if __name__ == "__main__":
    main()
